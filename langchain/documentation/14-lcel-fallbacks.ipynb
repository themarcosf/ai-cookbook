{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Handling LLM API Errors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llama_llm = Ollama(model=\"fake-model\")\n",
    "mistral_llm = Ollama(model=\"mistral\")\n",
    "llm = llama_llm.with_fallbacks([mistral_llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull fake-model`.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  llama_llm.invoke(\"Why did the chicken cross the road?\")\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The answer to this question is a classic example of a rhetorical question, which is a question asked for effect rather than expecting an answer. It\\'s not meant to be taken literally. However, if you insist on having a funny answer, there are numerous jokes and sayings about this question. Here\\'s one popular response: \"To get to the other side!\" But remember, it\\'s all in good fun.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Why did the chicken cross the road?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Specifying errors to handle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull fake-model`.\n"
     ]
    }
   ],
   "source": [
    "llm = llama_llm.with_fallbacks([mistral_llm], exceptions_to_handle=(KeyboardInterrupt,))\n",
    "\n",
    "try:\n",
    "  llama_llm.invoke(\"Why did the chicken cross the road?\")\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallbacks for Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're a nice assistant who always includes a compliment in your response\"),\n",
    "    (\"human\", \"Why did the {animal} cross the road\"),\n",
    "])\n",
    "\n",
    "fake_model = ChatOllama(model=\"fake-model\")\n",
    "fake_chain = chat_prompt | fake_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "                  Instructions: You should always include a compliment in your response.\n",
    "                  Question: Why did the {animal} cross the road?\n",
    "                  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "real_chain = prompt | mistral_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Answer: The turtle probably wanted to reach the other side of the road to explore new environments or access food and water sources. It's impressive how determined turtles can be in their journeys, overcoming various obstacles like roads with care and caution.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = fake_chain.with_fallbacks([real_chain])\n",
    "chain.invoke({\"animal\": \"turtle\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cookbook-DNsoNefS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
