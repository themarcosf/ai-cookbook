{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Code setup and Baseline language modeling\n",
    "\n",
    "### 1.1. Reading and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tiny_shakespear.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115393\n"
     ]
    }
   ],
   "source": [
    "print('length of dataset in characters: ', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Tokenization\n",
    "\n",
    "Trade-off: very long vocabulary size and very short sequences or very short vocabulary size and very long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  65\n",
      "vocab:  \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab size: ', vocab_size)\n",
    "print('vocab: ', ''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [46, 43, 50, 50, 53]\n",
      "decoded:  hello\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda string: [stoi[ch] for ch in string]\n",
    "decode = lambda tokens: ''.join([itos[t] for t in tokens])\n",
    "\n",
    "print('encoded: ', encode('hello'))\n",
    "print('decoded: ', decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.1. Production-grade example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  50257\n"
     ]
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding('gpt2')\n",
    "print('vocab size: ', enc.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [31373]\n",
      "decoded:  hello\n"
     ]
    }
   ],
   "source": [
    "print('encoded: ', enc.encode('hello'))\n",
    "print('decoded: ', enc.decode(enc.encode('hello')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.2. Tokenize `tiny shakespear` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tokenized text:  torch.Size([1115393])\n",
      "Dtype of tokenized text:  torch.int64\n",
      "First 10 characters:  First Citi\n",
      "First 10 tokens:  tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = torch.tensor(encode(text), dtype=torch.long)\n",
    "print('Shape of tokenized text: ', tokenized_text.shape)\n",
    "print('Dtype of tokenized text: ', tokenized_text.dtype)\n",
    "print('First 10 characters: ', text[:10])\n",
    "print('First 10 tokens: ', tokenized_text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3. `Train` and `Validation` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(tokenized_text) * 0.85)\n",
    "train_dataset = tokenized_text[:n]\n",
    "val_dataset = tokenized_text[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Data loader: batches of chunks of data\n",
    "\n",
    "**Note**: when a batch is created, each token dimension is an INFORMATION POINT in relation to the next token. Thus, each batch packs multiple examples in relation to the next token.\n",
    "\n",
    "Example:\n",
    "\n",
    "Block: [18, 47, 56, 57, 58,  1, 15, 47]\n",
    "Next token: 58\n",
    "\n",
    "1. Context: 18         -> 47 likely follows next\n",
    "2. Context: 18, 47     -> 56 likely follows next\n",
    "3. Context: 18, 47, 56 -> 57 likely follows next\n",
    "4. and so on...\n",
    "\n",
    "**TIME DIMENSION**: The idea behind training in this way is for the **transformer** to be able to predict the next token with as little as one token of context. Then, after `block_size`is reached, the inputs need to be truncated, because the **transformer** will never receive more than `block_size` tokens of context.\n",
    "\n",
    "**BATCH DIMENSION**: The idea behind batching is to train the model with multiple examples at the same time. This is done to speed up training and to make the model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 9 tokens:  tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n",
      "First block:  tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "Next token:  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "\n",
    "print('First 9 tokens: ', train_dataset[:context_length + 1])\n",
    "print('First block: ', train_dataset[:context_length])\n",
    "print('Next token: ', train_dataset[context_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  tensor([18])\n",
      "Target:  tensor(47)\n",
      "Context:  tensor([18, 47])\n",
      "Target:  tensor(56)\n",
      "Context:  tensor([18, 47, 56])\n",
      "Target:  tensor(57)\n",
      "Context:  tensor([18, 47, 56, 57])\n",
      "Target:  tensor(58)\n",
      "Context:  tensor([18, 47, 56, 57, 58])\n",
      "Target:  tensor(1)\n",
      "Context:  tensor([18, 47, 56, 57, 58,  1])\n",
      "Target:  tensor(15)\n",
      "Context:  tensor([18, 47, 56, 57, 58,  1, 15])\n",
      "Target:  tensor(47)\n",
      "Context:  tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "Target:  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "# time dimension\n",
    "\n",
    "x = train_dataset[:context_length]\n",
    "y = train_dataset[1:context_length+1]\n",
    "\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('Context: ', context)\n",
    "    print('Target: ', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  948084\n",
      "Sample of data:  tensor([18, 47, 56,  ..., 13, 57,  1])\n",
      "random_observations:  tensor([475443, 318696,  34022, 391054])\n",
      "Input batch:  tensor([[35, 46, 43, 52,  1, 23, 47, 52],\n",
      "        [53, 42, 63,  1, 57, 46, 39, 50],\n",
      "        [47, 52,  1, 21,  1, 51, 43, 43],\n",
      "        [43, 52, 58,  8,  0,  0, 16, 33]])\n",
      "Target batch:  tensor([[46, 43, 52,  1, 23, 47, 52, 45],\n",
      "        [42, 63,  1, 57, 46, 39, 50, 50],\n",
      "        [52,  1, 21,  1, 51, 43, 43, 58],\n",
      "        [52, 58,  8,  0,  0, 16, 33, 23]])\n",
      "Batch:  0 Time:  0\n",
      "Context:  tensor([35])\n",
      "Target:  tensor(46)\n",
      "Batch:  0 Time:  1\n",
      "Context:  tensor([35, 46])\n",
      "Target:  tensor(43)\n",
      "Batch:  0 Time:  2\n",
      "Context:  tensor([35, 46, 43])\n",
      "Target:  tensor(52)\n",
      "Batch:  0 Time:  3\n",
      "Context:  tensor([35, 46, 43, 52])\n",
      "Target:  tensor(1)\n",
      "Batch:  0 Time:  4\n",
      "Context:  tensor([35, 46, 43, 52,  1])\n",
      "Target:  tensor(23)\n",
      "Batch:  0 Time:  5\n",
      "Context:  tensor([35, 46, 43, 52,  1, 23])\n",
      "Target:  tensor(47)\n",
      "Batch:  0 Time:  6\n",
      "Context:  tensor([35, 46, 43, 52,  1, 23, 47])\n",
      "Target:  tensor(52)\n",
      "Batch:  0 Time:  7\n",
      "Context:  tensor([35, 46, 43, 52,  1, 23, 47, 52])\n",
      "Target:  tensor(45)\n"
     ]
    }
   ],
   "source": [
    "# batch dimension\n",
    "def get_batch(split, batch_size, verbose=False):\n",
    "    data = train_dataset if split == 'train' else val_dataset\n",
    "    if verbose:\n",
    "        print(\"Shape of data: \", len(data))\n",
    "        print('Sample of data: ', data)\n",
    "    \n",
    "    random_observations = torch.randint(0, len(data) - context_length, (batch_size,))\n",
    "    if verbose:\n",
    "        print(\"random_observations: \", random_observations)\n",
    "\n",
    "    input_batch = torch.stack([data[obs:obs+context_length] for obs in random_observations])\n",
    "    target_batch = torch.stack([data[obs+1:obs+context_length+1] for obs in random_observations])\n",
    "    \n",
    "    return input_batch, target_batch\n",
    "\n",
    "batch_size = 4\n",
    "input_batch, target_batch = get_batch('train', batch_size, True)\n",
    "print('Input batch: ', input_batch)\n",
    "print('Target batch: ', target_batch)\n",
    "\n",
    "for batch in range(batch_size):           # batch dimension\n",
    "    for time in range(context_length):    # time dimension\n",
    "        context = input_batch[batch, :time+1]\n",
    "        target = target_batch[batch, time]\n",
    "        if batch == 0:\n",
    "            print('Batch: ', batch, 'Time: ', time)\n",
    "            print('Context: ', context)\n",
    "            print('Target: ', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Simplest baseline: bigram language model\n",
    "\n",
    "**Note**: this implementation is ridiculous by design. As a simple *character-level* bigram model, the prediction throws away all context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  65\n",
      "Input batch shape:  torch.Size([4, 8])\n",
      "Target batch shape:  torch.Size([4, 8])\n",
      "Logits shape:  torch.Size([32, 65])\n",
      "Loss:  tensor(4.4551, grad_fn=<NllLossBackward0>)\n",
      "Inputs:  tensor([[35, 46, 43, 52,  1, 23, 47, 52]])\n",
      "Predicted targets:  tensor([ 1, 24, 33, 16, 57, 51, 54,  7,  5,  6, 54,  7, 15, 11, 20, 54, 54,  6,\n",
      "         9, 13,  9, 11, 15, 54,  5,  1, 56, 54,  9, 37, 15, 15, 27, 51, 33,  0,\n",
      "         7, 20, 54, 15,  0, 45, 15, 54, 49, 15, 28, 54, 15, 27])\n",
      "Predicted characters:   LUDsmp-',p-C;Hpp,3A3;Cp' rp3YCCOmU\n",
      "-HpC\n",
      "gCpkCPpCO\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        \"\"\"\n",
    "        `self.embedding` is 65 x 65, because for each of the 65 tokens in the vocabulary,\n",
    "        we have a 65-dimensional vector that represents the probability of the next token\n",
    "        given the context.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs, targets=None):\n",
    "        logits = self.embedding(inputs)    # B, T, C (batch, time, channels)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            _, _, C = logits.shape\n",
    "            logits = logits.view(-1, C)  # Flatten to [B * T, C]\n",
    "            targets = targets.view(-1)   # Flatten to [B * T]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, inputs, num_predictions):\n",
    "        predictions = torch.zeros(inputs.shape[0] * num_predictions, dtype=torch.long)\n",
    "\n",
    "        for i in range(num_predictions):\n",
    "            logits, _ = self(inputs)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            target = torch.multinomial(probs, num_samples=1)\n",
    "            predictions[i] = target\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(input_batch, target_batch)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "print('Input batch shape: ', input_batch.shape)\n",
    "print('Target batch shape: ', target_batch.shape)\n",
    "print('Logits shape: ', logits.shape)\n",
    "print('Loss: ', loss)\n",
    "\n",
    "NUM_PREDICTIONS = 50\n",
    "INPUTS = input_batch[:1]\n",
    "\n",
    "print('Inputs: ', INPUTS)\n",
    "predicted_targets = model.generate(INPUTS, NUM_PREDICTIONS)\n",
    "print('Predicted targets: ', predicted_targets)\n",
    "print('Predicted characters: ', decode(predicted_targets.tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Training the bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss 4.719812393188477\n",
      "Epoch 2000 | Loss 2.9696238040924072\n",
      "Epoch 4000 | Loss 2.6671085357666016\n",
      "Epoch 6000 | Loss 2.4390830993652344\n",
      "Epoch 8000 | Loss 2.452904462814331\n",
      "Loss 2.477780342102051\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(10000):\n",
    "    input_batch, target_batch = get_batch('train', batch_size)\n",
    "    logits, loss = model(input_batch, target_batch)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 2000 == 0:\n",
    "        print(f'Epoch {epoch} | Loss {loss.item()}')\n",
    "\n",
    "print(f'Loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  tensor([[57,  1, 39,  1, 57, 47, 41, 49]])\n",
      "Predicted characters:  \n",
      "neenieeee,u; ,iee n nese iesee . -es ,in iueie.e \n"
     ]
    }
   ],
   "source": [
    "NUM_PREDICTIONS = 50\n",
    "INPUTS = input_batch[:1]\n",
    "\n",
    "print('Inputs: ', INPUTS)\n",
    "predicted_targets = model.generate(INPUTS, NUM_PREDICTIONS)\n",
    "print('Predicted characters: ', decode(predicted_targets.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building the \"self-attention\" model\n",
    "\n",
    "### 2.1. `Version 1` - Weakest form of aggregation: averaging past context\n",
    "\n",
    "Each token in a batch should communicate information with other tokens in the batch, in such a way that information only flows from past tokens to the current token.\n",
    "\n",
    "Consider the fifth token in a batch of eight tokens. It should not communicate with tokens in the sixth, seventh and eighth positions, because those are FUTURE tokens in a sequence, but it should communicate with the fourth, third, second and first tokens, because those are PAST tokens in a sequence. This way, information only flows from previous context to the current timestep.\n",
    "\n",
    "Given this, the easiest way for tokens to communicate is to simply average all previous embeddings. This is the weakest form of aggregation and is extremely lossy, because all information about spatial arrangement of tokens is lost. \n",
    "\n",
    "This implementation is also very low performance, because it requires computation to be linear in the number of tokens in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of logits:  torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "logits = torch.randn(B, T, C)\n",
    "print(\"Shape of logits: \", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want bag of words be logits[b, t] = mean of logits[b, i] for i<=t\n",
    "logits_bow = torch.zeros((B, T, C))\n",
    "\n",
    "for batch in range(B):\n",
    "    for time in range(T):\n",
    "        logits_prev = logits[batch, :time+1]\n",
    "        logits_bow[batch, time] = torch.mean(logits_prev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits BOW shape:  torch.Size([4, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9618, -0.6699],\n",
       "         [ 0.1400,  1.8193],\n",
       "         [-0.2196,  2.5470],\n",
       "         [-1.4458,  0.0633],\n",
       "         [ 1.3801, -0.7089],\n",
       "         [-2.2699, -0.1819],\n",
       "         [ 1.6007,  0.8455],\n",
       "         [-0.4921, -1.3103]]),\n",
       " tensor([[-0.9618, -0.6699],\n",
       "         [-0.4109,  0.5747],\n",
       "         [-0.3472,  1.2321],\n",
       "         [-0.6218,  0.9399],\n",
       "         [-0.2215,  0.6101],\n",
       "         [-0.5629,  0.4781],\n",
       "         [-0.2538,  0.5306],\n",
       "         [-0.2836,  0.3005]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each location of logits_bow is the vertical mean of all previous logits\n",
    "print('Logits BOW shape: ', logits_bow.shape)\n",
    "logits[0], logits_bow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. The `mathematical trick` in self-attention: matrix multiplication with triangular mask\n",
    "\n",
    "Matrix multiplication is a very efficient way to calculate the dot product of each token with all other tokens. By masking the upper triangular part of the matrix, we can ensure that each token only communicates with previous tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b =\n",
      "tensor([[8., 9.],\n",
      "        [3., 1.],\n",
      "        [5., 9.]])\n",
      "---\n",
      "c =\n",
      "tensor([[16., 19.],\n",
      "        [16., 19.],\n",
      "        [16., 19.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print('a =')\n",
    "print(a)\n",
    "print('---')\n",
    "print('b =')\n",
    "print(b)\n",
    "print('---')\n",
    "print('c =')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the whole trick\n",
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b =\n",
      "tensor([[8., 9.],\n",
      "        [2., 5.],\n",
      "        [9., 9.]])\n",
      "---\n",
      "c =\n",
      "tensor([[8.0000, 9.0000],\n",
      "        [5.0000, 7.0000],\n",
      "        [6.3333, 7.6667]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, dim=1, keepdim=True)  # normalize\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print('a =')\n",
    "print(a)\n",
    "print('---')\n",
    "print('b =')\n",
    "print(b)\n",
    "print('---')\n",
    "print('c =')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. `Version 2` - Self-attention with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / torch.sum(weights, dim=1, keepdim=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits BOW 2 shape:  torch.Size([4, 8, 2])\n",
      "Logits BOW == Logits BOW 2?  True\n"
     ]
    }
   ],
   "source": [
    "logits_bow_2 = weights @ logits\n",
    "print('Logits BOW 2 shape: ', logits_bow_2.shape)\n",
    "print('Logits BOW == Logits BOW 2? ', torch.allclose(logits_bow, logits_bow_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. `Version 3`: Self-attention adding softmax\n",
    "\n",
    "The softmax function exponentiates each element and normalizes the results so that they sum up to **1** along the specified dimension. Since &minus;&infin; values correspond to zeros when exponentiated, the softmax ensures that the attention is focused only on the elements allowed by the lower triangular mask.\n",
    "\n",
    "An important aspect to note here is that the weights are initialized as `zeroes`, giving room for future `affinities` between tokens to be data dependent. That is, they will start looking at each other and some tokens will find other tokens more or less interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.zeros(T, T)\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = F.softmax(weights, dim=1)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits BOW 3 shape:  torch.Size([4, 8, 2])\n",
      "Logits BOW == Logits BOW 3?  True\n"
     ]
    }
   ],
   "source": [
    "logits_bow_3 = weights @ logits\n",
    "print('Logits BOW 3 shape: ', logits_bow_3.shape)\n",
    "print('Logits BOW == Logits BOW 3? ', torch.allclose(logits_bow, logits_bow_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. `Version 4`: THE CRUX OF IT ALL - Self-attention with `affinities`\n",
    "\n",
    "In previous versions, all past tokens are averaged in the context of the current token, resulting in uniform affinities. But self-attention is all about learning data-dependent affinities between tokens so that, for example, a *vowel* token might look for *consonants* in its past and might want to know what those consonants were and let this data to flow to the current token.\n",
    "\n",
    "In order to solve this data dependency problem, every single token in self-attention will emit two vectors:\n",
    "- **Query**: roughly speaking is \"What am I looking for?\"\n",
    "- **Key**: roughly speaking is \"What do I contain?\"\n",
    "\n",
    "These vectors will be produced in parallel and independently by two linear transformations of the token embeddings. After creation, they will communicate through a dot product, resulting in a scalar value that will be used as the **affinity** between tokens. If the `Key` and the `Query` are very similar, the dot product will be high and the value of the token will be weighted more.\n",
    "\n",
    "Finally, for the aggregations to be calculated, the `Value` vector is created by a third linear transformation of the token embeddings. This way, the logits become private information of the token and the aggregation is done by a weighted sum of the `Value` vector. Roughly speaking, \"If you find me interesting, this is what I will communicate to you.\"\n",
    "\n",
    "Important notes about self-attention:\n",
    "- Attention is a **communication mechanism**. It can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other.\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=2, out_features=1, bias=False),\n",
       " Linear(in_features=2, out_features=1, bias=False),\n",
       " Linear(in_features=2, out_features=1, bias=False))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation of a single head self-attention mechanism\n",
    "head_size = 1\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "key, query, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 1]),\n",
       " torch.Size([4, 8, 1]),\n",
       " torch.Size([4, 8, 1]),\n",
       " torch.Size([4, 8, 8]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication of key and query to get the weights\n",
    "# NOTE: previously, weights were initialized as `zeroes` and then masked\n",
    "k = key(logits)\n",
    "q = query(logits)\n",
    "v = value(logits)\n",
    "weights = q @ k.transpose(-2, -1)\n",
    "k.shape, q.shape, v.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2441, 0.7559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0967, 0.3937, 0.5096, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3368, 0.1882, 0.1692, 0.3058, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1814, 0.2159, 0.2229, 0.1867, 0.1931, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2389, 0.0812, 0.0666, 0.1998, 0.1620, 0.2513, 0.0000, 0.0000],\n",
       "        [0.0669, 0.2183, 0.2713, 0.0814, 0.1024, 0.0633, 0.1963, 0.0000],\n",
       "        [0.1712, 0.0642, 0.0536, 0.1455, 0.1202, 0.1793, 0.0701, 0.1959]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_bow_4 = weights @ v\n",
    "logits_bow_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building the transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cookbook-DNsoNefS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
