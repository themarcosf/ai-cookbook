{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Base case tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "plaintext = 'happy'\n",
    "cyphertext = 'ogatzAKtNKEvabbzM7kUig=='\n",
    "\n",
    "tokenizer_ckpt = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_ckpt)\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(plaintext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 3407, 102]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(plaintext)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'happy': 3407}, {'ogatzAKtNKEvabbzM7kUig==': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRA IMPORTANT GOTCHA HERE! WHY IS THE ID 1?\n",
    "token = tokenizer.tokenize(plaintext)[0]\n",
    "id = tokenizer(plaintext)['input_ids'][1]\n",
    "\n",
    "plain_to_index = { token: id }\n",
    "cypher_to_index = { cyphertext: 1 }\n",
    "\n",
    "plain_to_index, cypher_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'happy': 'ogatzAKtNKEvabbzM7kUig=='}, {'ogatzAKtNKEvabbzM7kUig==': 'happy'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_to_cypher = { token: cyphertext }\n",
    "cypher_to_plain = { cyphertext: token }\n",
    "\n",
    "plain_to_cypher, cypher_to_plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Token masking and remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model_ckpt = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_ckpt)\n",
    "model.config.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distilbert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = model.distilbert.embeddings.word_embeddings\n",
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy -> 3407\n",
      "Embeddings shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "plain_embeddings = {}\n",
    "\n",
    "for k, v in plain_to_index.items():\n",
    "    print(f'{k} -> {v}')\n",
    "\n",
    "    emb = word_embeddings(torch.tensor(v))\n",
    "    print('Embeddings shape:', emb.shape)\n",
    "\n",
    "    plain_embeddings[k] = emb.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogatzAKtNKEvabbzM7kUig== -> 1\n",
      "Embeddings shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "cypher_embeddings = {}\n",
    "\n",
    "for k, v in cypher_to_index.items():\n",
    "    print(f'{k} -> {v}')\n",
    "\n",
    "    plain = cypher_to_plain[k]\n",
    "\n",
    "    emb = word_embeddings(torch.tensor(plain_to_index[plain]))\n",
    "    print('Embeddings shape:', emb.shape)\n",
    "\n",
    "    cypher_embeddings[k] = emb.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_embeddings[plaintext] == cypher_embeddings[cyphertext]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessor\n",
    "\n",
    "## 3.1. Dataset for preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CypherEmbeddingDataset(Dataset):\n",
    "    def __init__(self, cypher_to_index, cypher_embeddings):\n",
    "        self.cypher_to_index = cypher_to_index\n",
    "        self.cyphers = list(cypher_embeddings.keys())\n",
    "        self.embeddings = [torch.tensor(cypher_embeddings[cypher]) for cypher in self.cyphers]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cyphers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cypher = self.cyphers[idx]\n",
    "        cypher_index = self.cypher_to_index[cypher]\n",
    "        embedding = self.embeddings[idx]\n",
    "        return torch.tensor(cypher_index), embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Index: tensor([1])\n",
      "Embeddings: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "dataset = CypherEmbeddingDataset(cypher_to_index, cypher_embeddings)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for index, embeddings in dataloader:\n",
    "    print(\"Cypher Index:\", index)\n",
    "    print(\"Embeddings:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Class definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Preprocessor, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, indices):\n",
    "        return self.embedding(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [600/6000], Loss: 0.4065\n",
      "Epoch [1200/6000], Loss: 0.1609\n",
      "Epoch [1800/6000], Loss: 0.0621\n",
      "Epoch [2400/6000], Loss: 0.0227\n",
      "Epoch [3000/6000], Loss: 0.0077\n",
      "Epoch [3600/6000], Loss: 0.0023\n",
      "Epoch [4200/6000], Loss: 0.0005\n",
      "Epoch [4800/6000], Loss: 0.0001\n",
      "Epoch [5400/6000], Loss: 0.0000\n",
      "Epoch [6000/6000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(vocab_size=tokenizer.vocab_size, embedding_dim=model.config.dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(preprocessor.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 6000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for idx, embedding in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = preprocessor(idx)\n",
    "        loss = criterion(outputs, embedding)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 600 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = word_embeddings(torch.tensor(plain_to_index[plaintext]))\n",
    "output = preprocessor(torch.tensor(cypher_to_index[cyphertext]))\n",
    "torch.allclose(embeddings, output, rtol=1e-06, atol=1e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(embeddings, output, rtol=1e-06, atol=1e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "torch.save(obj=preprocessor.state_dict(), f='./models/preprocessor.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cookbook-DNsoNefS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
